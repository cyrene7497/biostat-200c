---
title: "Biostat 200C Final"
author: "Cyrene Arputhasamy (UID 705-527-395)"
subtitle: Due June 16, 2023 @ 11:59PM
output:
  html_document:
    toc: yes
    toc_depth: 4
    keep_tex: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
library(tidyverse)
library(faraway)
library(survival)
library(ggfortify)
library(MASS)
library(lme4)
library(geepack)
```

This is an open book test. Helping or asking help from others is considered plagiarism. 

## Q1. (25 pts) Survival data analysis

Consider following survival times of 25 patients with no history of chronic diesease (`chr = 0`) and 25 patients with history of chronic disease (`chr = 1`).

Group 1 (chr=0): 12.3+, 5.4, 8.2, 12.2+, 11.7, 10.0, 5.7, 9.8, 2.6, 11.0, 9.2, 12.1+, 6.6, 2.2, 1.8, 10.2, 10.7, 11.1, 5.3, 3.5, 9.2, 2.5, 8.7, 3.8, 3.0.

Group 2 (chr=1): 5.8, 2.9, 8.4, 8.3, 9.1, 4.2, 4.1, 1.8, 3.1, 11.4, 2.4, 1.4, 5.9, 1.6, 2.8, 4.9, 3.5, 6.5, 9.9, 3.6, 5.2, 8.8, 7.8, 4.7, 3.9.

`+` indicates right-censored times

1. Manually fill in the missing information in the following tables of ordered failure times for groups 1 (`chr = 0`) and 2 (`chr = 1`). Explain how survival probabilities (last column) are calculated.

Group 1 (`chr = 0`):

| time | n.risk | n.event | survival |
|------|--------|---------|----------|
| 1.8  | 25     | 1       | 0.96     |
| 2.2  | 24     | 1       | 0.92     |
| 2.5  | 23     | 1       | 0.88     |
| 2.6  | 22     | 1       | 0.84     |
| 3.0  | 21     | 1       | 0.80     |
| 3.5  | 20     | 20-19 = **1** | (20-1)/25 = **0.76**  |
| 3.8  | 19     | 1       | 0.72     |
| 5.3  | 18     | 1       | 0.68     |
| 5.4  | 17     | 1       | 0.64     |
| 5.7  | 16     | 1       | 0.60     |
| 6.6  | 15     | 1       | 0.56     |
| 8.2  | 14     | 1       | 0.52     |
| 8.7  | 13     | 1       | 0.48     |
| 9.2  | 13-1 = **12** | 12-10 = **2** | (12-2)/25 = **0.4** |
| 9.8  | 10     | 1       | 0.36     |
| 10.0 | 9      | 1       | 0.32     |
| 10.2 | 8      | 1       | 0.28     |
| 10.7 | 7      | 1       | 0.24     |
| 11.0 | 6      | 1       | 0.20     |
| 11.1 | 5      | 1       | 0.16     |
| 11.7 | 4      | **1** | 3/25= **0.12**  |

Group 2 (`chr = 1`):

| time | n.risk | n.event | survival |
|------|--------|---------|----------|
| 1.4  | 25     | 1       | 0.96     |
| 1.6  | 24     | 1       | 0.92     |
| 1.8  | 23     | 1       | 0.88     |
| 2.4  | 22     | 1       | 0.84     |
| 2.8  | 21     | 1       | 0.80     |
| 2.9  | 20     | 1       | 0.76     |
| 3.1  | 19     | 1       | 0.72     |
| 3.5  | 18     | 1       | 0.68     |
| 3.6  | 17     | 1       | 0.64     |
| 3.9  | 17-1 = **16** | **1** | 15/25= **0.6** |
| 4.1  | **15** | **1** | 14/25= **0.56** |
| 4.2  | **14** | **1** | 13/25 = **0.52** |
| 4.7  | 13     | 1       | 0.48     |
| 4.9  | 12     | 1       | 0.44     |
| 5.2  | 11     | 1       | 0.40     |
| 5.8  | 10     | 1       | 0.36     |
| 5.9  | 9      | 1       | 0.32     |
| 6.5  | 8      | 1       | 0.28     |
| 7.8  | 7      | 1       | 0.24     |
| 8.3  | 6      | 1       | 0.20     |
| 8.4  | 5      | 1       | 0.16     |
| 8.8  | 4      | 1       | 0.12     |
| 9.1  | 4-1 = **3** | 3-(.08x25) = **1** | 0.08    |
| 9.9  | .08x25= **2** | 2-1= **1** | 0.04    |
| 11.4 | 1      | 1       | 0.00     |

The estimate of the survival is computed as:
$$
\widehat{S}(y_{(j)}) = \prod_{i = 1}^j \bigg(\frac{n_i - d_i}{n_i} \bigg)
$$
Survival probabilities are calculated by (`n.risk` - `n.event`)/(n.risk at first time point) where `n.risk` is the number at risk and `n.event` is the number of events at that time point. In this case, the number at risk at the first time point is 25. 

2. Use R to display the Kaplan-Meier survival curves for groups 1 (`chr = 0`) and 2 (`chr = 1`). 
```{r}
chronic <- list("time" = c(1.8, 2.2, 2.5, 2.6, 3.0, 3.5, 3.8, 5.3, 5.4, 5.7, 6.6,
                           8.2, 8.7, 9.2, 9.2, 9.8, 10.0, 10.2, 10.7, 11.0, 11.1,
                           11.7, 12.1, 12.2, 12.3, 1.4, 1.6, 1.8, 2.4, 2.8, 2.9,
                           3.1, 3.5, 3.6, 3.9, 4.1, 4.2, 4.7, 4.9, 5.2, 5.8, 5.9,
                           6.5, 7.8, 8.3, 8.4, 8.8, 9.1, 9.9, 11.4),
                "cens" = c(2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,2,2,
                           2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2),
                "chr" = c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,
                          1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1))

kmfit <- chronic %>% as.data.frame() %>% survfit(Surv(time,cens) ~ chr, data = .)
kmfit %>% autoplot()
```

3. Write down the log-likelihood of the parametric exponential (proportional hazard) model for survival times. Explain why this model can be fit as a generalized linear model with offset.

The log-likelihood of the proportional hazard model for survival times is
$$
\ell(\boldsymbol{\beta}) = \sum_j (\delta_j \cdot \mathbf{x}_j^T \boldsymbol{\beta} - y_j e^{\mathbf{x}_j^T \boldsymbol{\beta}}) = \sum_j \left\{ \delta_j \cdot [\mathbf{x}_j^T \boldsymbol{\beta} + \log(y_j)] - y_j e^{\mathbf{x}_j^T \boldsymbol{\beta}} - \delta_j \log(y_j) \right\}.
$$
This model's log-likelihood resembles the log-likelihood of a Poisson distribution (which is a generalized linear model) if we treat $\delta_j$ as Poisson$(\mu_j)$ where $\mu_j = \theta_j y_j$. If we use the log-link then 
$$
\log(\mu_j) = log(\theta_j) + \log(y_j)
$$
then survival times $y_j$ are included in the model as an offset term $\log(y_j)$. 

4. Fit the exponential (proportional hazard) model on the `chr` data using R. Interpret the coefficients.
```{r}
glm(cens ~ as.factor(chr) + offset(log(time)), family = poisson, data = chronic) %>%
  summary()
```
To interpret the coefficients, in a proportional hazards model, $e^{-\beta_j}$ gives the hazard ratio of comparing two levels. Therefore the hazard of history of chronic disease is $e^{0.4198} = 1.52$ times the hazard of not having a history of chronic disease, or 52% higher.  

5. Comment on the limitation of exponential model compared to other more flexible models such as Weibull.

The densities of the Weibull distribution and exponential distribution are very similar. When $\lambda = 1$ in the Weibull model, this corresponds to the exponential distribution. The hazard function in the exponential model doesn't depend on $y$ while the hazard function in the Weibull distribution does depend on $y$. This is a limitation of the exponential model since the probability of failure often is related to time and even likely increases with time. The Weibull model is more flexible since we can model both increasing and decreasing Weibull models. In an increasing Weibull model, as survival time increases, the probability of death increases as well (for example, survival of a cancer patient not responding to treatment). In a decreasing Weibull model, as survival time increases, the probability of death decreases (for example, survival of a patient after a successful surgery).  

## Q2 (25 pts). (Longitudinal data analysis) 

Onychomycosis, popularly known as toenail fungus, is a fairly common condition that not only can disfigure and sometimes destroy the nail but that also can lead to social and self-image issues for sufferers. Tight-fitting shoes or hosiery, the sharing of common facilities such as showers and locker rooms, and toenail polish are all thought to be implicated in the development of onychomycosis. This question relates to data from a study conducted by researchers that recruited sufferers of a particular type of onychomycosis, dermatophyte onychomycosis. The study conducted by the researchers was focused on comparison of two oral medications, terbinafine (given as 250 mg/day, denoted as treatment 1 below) and itraconazole (given as 200 mg/day, denoted as treatment 2 below). 

The trial was conducted as follows. 200 sufferers of advanced toenail dermatophyte onychomycosis in the big toe were recruited, and each saw a physician, who removed the afflicted nail. Each subject was then randomly assigned to treatment with either terbinafine (treatment 1) or itraconazole (treatment 2). Immediately prior to beginning treatment, the length of the unafflicted part of the toenail (which was hence not removed) was recorded (in millimeters). Then at 1 month, 2 months, 3 months, 6 months, and 12 months, each subject returned, and the length of the unafflicted part of the nail was measured again. A longer unafflicted nail length is a better outcome. Also recorded on each subject was gender and an indicator of the frequency with which the subject visited a gym or health club (and hence might use shared locker rooms and/or showers).

The data are available in the file `toenail.txt` from [here](https://ucla.box.com/s/brb3vz4nwoq8pjkcutxncymqw583d39l). The data are presented in the form of one data record per observation; the columns of the data set are as follows:
```{r}
library(dplyr)
toe <- read.table("toenail.txt", header = FALSE, sep = "", dec = ".")
toe <- toe %>% dplyr::rename(id = V1, healthcl_fr = V2, gender = V3, month = V4, unail_len = V5, treatment = V6)
toe %>% head(5)
```

1. Subject id

2. Health club frequency indicator (= 0 if once a week or less, = 1 if more than once a week)

3. Gender indicator (= 0 if female, = 1 if male)

4. Month

5. Unafflicted nail length (the response, mm)

6. Treatment indicator (= 1 if terbinafine, = 2 if itraconazole)

The researchers had several questions, which they stated to you as follows:


1. Use the linear mixed effect model (LMM) to answer: Is there a difference in the pattern of change of lengths of the unafflicted part of the nail between subjects receiving `terbinafine` and `itraconazole` over a 12 month period? Does one treatment show results more quickly?  
    
    - Plot the change of lengths of the unafflicted part of the nail over time and separated by treatment groups. Comment on overall patterns over time.
```{r}
treat.labs <- c("terbinafine", "itraconazole")
names(treat.labs) <- c("1", "2")
ggplot(data = toe) +
  geom_line(mapping = aes(x = month, y = unail_len, group = id)) +
  facet_wrap(~ treatment, labeller = labeller(treatment = treat.labs))
ggplot(data = toe, 
       aes(x = month, y = unail_len, group = treatment, col = as.factor(treatment))) + 
  stat_summary(geom = "line", fun.y = mean) + 
  labs(x = "Month", y = "Average Untreated Nail Length",
                      title = "Untreated Nail Length Over Time by Treatment",
                      col = "Treatment") +
  scale_color_manual(values = c("1" = "red", "2" = "blue"),
                     labels = c("terbinafine", "itraconazole")) +
  theme(legend.position = "right")
```
  There's a lot of variability in each individual's trend. They all have different initial untreated nail lengths. Both treatments have a generally positive trend by individual, but when we take the average over the treatment groups, we see that the second treatment, `itraconazole` might support untreated nail length more than `terbinafine`. 

    - Based on the pattern observed, pick appropriate time trend in the LMM and provide an algebraic definition for your chosen LMM, e.g., is the linear trend model adequate? or quadratic trend is needed? or any other pattern is more approriate? justify your answer. 
  
  Based on the observed pattern, the time variable might not be completely linear and might need to be treated as piece-wise (as a factor) since the slope is variable within an individual's trend.
```{r}
tnmod1 <- lmer(unail_len ~ treatment + month + (1 | id), data = toe)
ttmod1 <- lmer(unail_len ~ treatment + as.factor(month) + (1 | id), data = toe)
library(pbkrtest)
KRmodcomp(tnmod1, ttmod1)
```
The highly insignificant p-value suggests that treating the `month` variable as a factor variable (as a piece-wise function) is not preferable.

```{r}
tcmod1 <- lmer(unail_len ~ treatment + month + I(month^2) + (1 | id), data = toe)
KRmodcomp(tcmod1, tnmod1)
```
The insignificant p-value suggests that including the `month` variable as a quadratic variable is not preferable. Therefore we continue with `month` as a linear term and include the random intercept for each subject ID.

In the suggested random intercept model:

$$
\text{nail length} = treatment\beta_1 + month\beta_2 + id\gamma + \epsilon, \epsilon_i \sim N(0, \sigma^2)
$$
    
    - Model the covariance: fit both random intercept and random slope model and determine which one fits the data better. 
```{r}
summary(tnmod1)
toelmm2 <- lmer(unail_len ~ treatment + (month | id), data = toe)
summary(toelmm2)
```
    The model with the random slope fits the data better since that model captures more variability than the residuals. The variances of the random effects are higher than the residual variance. In the model with only a random intercept, the residual variance is higher so the model didn't capture the variability as well. 

2. Use the linear mixed effect model (LMM) to answer: Is there an association between the pattern of change of nail lengths and gender and/or health club frequency in subjects taking `terbinafine`? This might indicate that this drug brings about relief more swiftly in some kinds of subject versus others.
```{r}
toe_t <- toe %>%
  filter(treatment == 1)
```


    - Provide graphs to show patterns the change of nail lengths and gender and/or health club frequency in subjects taking terbinafine. 
```{r}
gender.labs <- c("female", "male")
names(gender.labs) <- c("0", "1")
ggplot(data = toe_t) +
  geom_line(mapping = aes(x = month, y = unail_len, group = id)) +
  facet_wrap(~ gender, labeller = labeller(gender = gender.labs))
ggplot(data = toe_t, 
       aes(x = month, y = unail_len, group = gender, col = as.factor(gender))) + 
  stat_summary(geom = "line", fun.y = mean) + 
  labs(x = "Month", y = "Average Untreated Nail Length",
                      title = "Untreated Nail Length Over Time with Terbinafine by Gender",
                      col = "Gender") +
  scale_color_manual(values = c("0" = "red", "1" = "blue"),
                     labels = c("female", "male")) +
  theme(legend.position = "right")
```
    Males might respond to the drug more quickly than females, but their overall trajectory is similar.
    
```{r}
health.labs <- c("once a week or less", "more than once a week")
names(health.labs) <- c("0", "1")
ggplot(data = toe_t) +
  geom_line(mapping = aes(x = month, y = unail_len, group = id)) +
  facet_wrap(~ healthcl_fr, labeller = labeller(healthcl_fr = health.labs))
ggplot(data = toe_t, 
       aes(x = month, y = unail_len, group = healthcl_fr, col = as.factor(healthcl_fr))) + 
  stat_summary(geom = "line", fun.y = mean) + 
  labs(x = "Month", y = "Average Untreated Nail Length",
                      title = "Untreated Nail Length Over Time with Terbinafine by Health Club Frequency",
                      col = "Health Club Frequency") +
  scale_color_manual(values = c("0" = "red", "1" = "blue"),
                     labels = c("once a week or less", "more than once a week")) +
  theme(legend.position = "right")
```
Generally those who go to a health club once a week or less see longer length of untreated nails, but the slopes are similar suggesting that the rate of recovery is the same but just the initial length is different.
    
    - Based on the pattern observed from question 1, pick appropriate time trend in the LMM and provide an algebraic definition for your chosen LMM, e.g., is the linear trend model adequate? or quadratic trend is needed? or any other pattern is more approriate? justify your answer. 

**Concerning `gender`:**

Because the lines go up and down over time, a piece-wise linear model might be a more appropriate time trend. 
```{r}
tnmod2 <- lmer(unail_len ~ gender + month + (1 | id), data = toe)
ttmod2 <- lmer(unail_len ~ gender + as.factor(month) + (1 | id), data = toe)
KRmodcomp(tnmod2, ttmod2)
```
The highly insignificant p-value suggests that treating the `month` variable as a factor variable (as a piece-wise function) is not preferable in the model including `gender`.

```{r}
tcmod2 <- lmer(unail_len ~ gender + month + I(month^2) + (1 | id), data = toe)
KRmodcomp(tnmod2, tcmod2)
```
The high p-value suggests that treating the `month` variable as linear only is preferable in the model that includes `gender`.

**Concerning `healthcl_fr` (health club frequency):**

```{r}
tnmod3 <- lmer(unail_len ~ healthcl_fr + month + (1 | id), data = toe)
ttmod3 <- lmer(unail_len ~ healthcl_fr + as.factor(month) + (1 | id), data = toe)
KRmodcomp(tnmod3, ttmod3)
```
The high p-value suggests that it is not preferable to treat `month` as a piece-wise function. 
```{r}
tcmod3 <- lmer(unail_len ~ healthcl_fr + month + I(month^2) + (1 | id), data = toe)
KRmodcomp(tnmod3, tcmod3)
```
The high p-value suggests that it is preferable in this model to include `month` only as a linear term.

Therefore the suggested models with a random intercept are: 
$$
\text{nail length} = gender\beta_1 + month\beta_2 + id\gamma_1 + \epsilon, \epsilon_i \sim N(0, \sigma^2)\\
\\
\text{nail length} = healthclub\beta_1 + month\beta_2 + id\gamma_1 + \epsilon, \epsilon_i \sim N(0, \sigma^2)
$$
    
    - Model the covariance: fit both random intercept and random slope model and determine which one fits the data better. 
```{r}
summary(tnmod2)
toetlmm2 <- lmer(unail_len ~ gender + (month | id), data = toe_t)
summary(toetlmm2)
```
The model with both a random slope and random intercept fits the data better suggesting that each individual does have a variable recovery time by gender. The residual random variance goes down a lot when the random slope is included. 

```{r}
summary(tnmod3)
toetlmm4 <- lmer(unail_len ~ healthcl_fr + (month | id), data = toe_t)
summary(toetlmm4)
```
The model with both a random slope and random intercept fits the data better suggesting that each individual does have a variable recovery time by health club frequency. The residual random variance goes down very much when the random slope is included. 

3. In answering these scientific questions of interest, clearly write out the analytic models you consider for answering these questions (as detailed in the sub-questions). Clearly outline your decision making process for how you selected your final models. Fit your chosen final models and report to the project investigators on the stated scientific questions of interest.

We've considered all the possible models including a quadratic term for `month`, combined into a full model as follows:
$$
\text{nail length} = treatment\beta_1 + gender\beta_2 + healthclub\beta_3 + month\beta_4 + month^2\beta_5 + id\gamma_1 + \epsilon, \epsilon_i \sim N(0, \sigma^2)
$$
and also considered the model with random slope as follows:
$$
\text{nail length} = treatment\beta_1 + gender\beta_2 + healthclub\beta_3 + month\beta_4 + month^2\beta_5 + id\gamma_1 + month\gamma_2 + \epsilon, \epsilon_i \sim N(0, \sigma^2)
$$
In answering these questions, I considered the trends of each individual since individuals might respond to the types of treatment differently. We saw that there was a difference in the pattern of change of lengths of the unafflicted part of the nail between subjects receiving terbinafine and itraconazole over a 12 month period. Itraconazole showed results more quickly based on the interpretation of the fixed effect of treatment 2 in the model with random slope and random intercept. Those who were on treatment 2 (itraconazole) saw .38 (treatment coefficient) mm more growth on average than those treated with terbinafine, all else constant. Among those treated with terbinafine, men have a slightly higher nail growth than women based on the positive slope coefficient. The coefficient for health club frequency is negative, with the reference group being those who go to the health club once a week or less, so there is less untreated nail growth in those who go to the health club more frequently. The final chosen model can include all of these variables with a random slope and random intercept, with time included only linearly. The terbinafine drug seems to bring about relief more swiftly to men and those who go to the health club less frequently.

The final model is:

$$
\text{nail length} = treatment\beta_1 + gender\beta_2 + healthclub\beta_3 + month(\beta_4 + \gamma_2) + id\gamma_1 + \epsilon, \epsilon_i \sim N(0, \sigma^2)
$$

```{r}
toelmmf <- lmer(unail_len ~ treatment + gender + healthcl_fr + (month | id), data = toe)
summary(toelmmf)
```
In the final model, the random residuals are less than the random intercept and random slope so the model has a good fit and captures a lot of the variability. The trends in the full model are consistent with the marginal trends. Those in treatment group 2 (Itraconazole) have a faster nail growth than those in group 1 (treated with terbinafine) when all else is constant. Those treated with itraconazole had .40 mm more nail growth on average than those treated with terbinafine, all else constant. Males treated with terbinafine who went to a health club once a week or less have .2mm more nail growth than women in the same category on average, all else constant. And men treated with terbinafine who attend health clubs more than once a week have 1.11 less nail growth on average than those who go less frequently, all else constant. 

## Q3 (25 pts). (GEE and GLMM) 

The Skin Cancer Prevention Study, a randomized, double-blind, placebo-controlled clinical trial, was designed to test the effectiveness of beta-carotene in the prevention of non-melanoma skin cancer in high-risk subjects. A total of 1,683 subjects were randomized to either placebo or 50mg of beta-carotene per day and were followed for up to 5 years. Subjects were examined once per year and biopsied if a cancer was suspected to determine the number of new cancers per year. The outcome variable, $Y$, is a count of the number of new skin cancers per year. You may assume that the counts of new skin cancers, $Y$, are from exact one-year periods (so that no offset term is needed).

Selected data from the study are in the dataset called `skin.txt` and is available [here](https://ucla.box.com/s/brb3vz4nwoq8pjkcutxncymqw583d39l). Each row of the dataset contains the following 9 variables: ID, Center, Age, Skin, Gender, Exposure, $Y$, Treatment, Year. These variables take values as follows:

| Variable |  |
| ----------------- | ------------------------- |
|**ID**:            | Subject identifier number |
|**Center**:        | Identifier number for center of enrollment|
|**Age:**         | Subject’s age in years at randomization|
|**Skin:**        |Skin type (1=burns; 0 otherwise) [evaluated at randomization and doesn’t change with time]|
|**Gender:**      |1=male; 0=female| 
|**Exposure:**    |Count of number of previous skin cancers [prior to randomization]|
|**$Y$:**           |Count of number of new skin cancers in the Year of follow-up|
|**Treatment:**   |1=beta-carotene; 0=placebo|
|**Year:**        |Year of follow-up after starting randomized treatment|


Your collaborator is interested in assessing the effect of treatment on the incidence of new 
skin cancers over time. As the statistician on the project, provide an analysis of the data
that addresses this question. Specifically, the investigator at Center=1 is interested in characterizing the distribution of risk among subjects at her center. In the following, only include the subset of subjects with Center=1 in the analysis.
```{r}
skin <- read.table("skin.txt", header = FALSE, sep = "")
skin <- skin %>% dplyr::rename(id = V1, center = V2, age = V3, skintype = V4, gender = V5,
                        exposure = V6, num_new = V7, treatment = V8, year = V9)
skin %>% head(3)
skin1 <- skin %>%
  filter(center == 1)
```

1. Provide an algebraic definition for a generalized linear marginal model in which the only effects are for the intercept and Year (as a continuous variable). Fit this model and provide a table which includes the estimates of the parameters in your model.

$$
\text{number of new skin cancers} = e^{X\beta} = e^{\beta_0 + year\beta_1}
$$

```{r}
skinmod1 <- glm(num_new ~ year, family = poisson, data = skin1)
summary(skinmod1)
library(gtsummary)
skinmod1 %>%
  tbl_regression(exponentiate = TRUE, intercept = TRUE)
```

     
2. Provide an algebraic definition for a generalized linear mixed model (GLMM) in which the only fixed effects are for the intercept and Year (as a continuous variable), and the only random effect is the intercept. What is being assumed about how the distribution of risk among subjects changes with time?

$$
\text{number of new skin cancers} = e^{X\beta + Z\gamma} = e^{\beta_0 + year\beta_1 + id\gamma_0 + \epsilon}, \epsilon_i \sim N(0, \sigma^2)
$$
The only random effect is an intercept for every subject ID. This model assumes that risk is distributed multivariate normal among subjects. It also assumed that the slopes of each individual are roughly the same. 
     
3. Fit your chosen GLMM and provide a table from your output which includes the estimates for the parameters in your GLMM, and provide careful interpretation of the `Year` term.
```{r}
skinmod2 <- glmer(num_new ~ year + (1 | id), family = poisson, data = skin1)
summary(skinmod2)
```
For every additional year of follow-up after the beginning of the experiment at center 1, the average number of new skin cancer decreases by roughly 11% ($e^{-0.1083} = 0.89$) all else held constant. 

4. Are the estimates for the fixed intercept terms the same or different in the GLMM compared with the marginal model fitted in question (1)? Why are they the same or different?

The estimated for the fixed intercept terms are different in the GLMM compared to the marginal model fitted in question 1 because some of the randomness and variability of the intercept is now included in the random intercept model instead of just the fixed intercept. 
     
5. Use the parameter estimates from your GLMM and your model definition to characterize the distribution of expected counts of new skin cancers among subjects at center 1 during their first year of follow-up.

For the poisson distribution, there is only one parameter $\lambda$ which is estimated by $\eta = log \mu = x^T\beta$ so by exponentiating the $\beta$ coefficient we get $\lambda = e^{-0.1083} = 0.89$ so the distribution is Poisson($\lambda = 0.89$).

## Q4. (25 pts) LMM and GAMM

This question is adapted from Exercise 11.2 of ELMR (p251). Read the documentation of the dataset `hprice` in Faraway package before working on this problem.
```{r}
hprice %>% head(5)
```

1. Make a plot of the data on a single panel to show how housing prices increase by year. Describe what can be seen in the plot.

The average sale price (`narsp`) is collected as natural log of the average sale price in thousands of dollars so we exponentiate values to show how raw average housing prices change by year. In the graph below there is one line per MSA (Metropolitan statistical area) over 9 years from 1986-1944. 

```{r}
hprice %>%
  ggplot() + 
  geom_line(mapping = aes(x = time, y = exp(narsp), color = msa),
            show.legend = FALSE) +
  scale_x_continuous("Year", 
                     labels = c("1986", "1988", "1990", "1992", "1994")) +
  ylab("Average Sale Price in Thousands of Dollars") 
```

It's apparent that different MSAs have different average starting prices for houses. It also seems like every MSA has a generally increasing trend although they have different trajectories. Due to the different starting prices, we will probably include a random intercept in the model. 

2. Fit a linear model with the (log) house price as the response and all other variables (except msa) as fixed effect predictors. Which terms are statistically significant? Discuss the coefficient for time.
```{r}
lm1 <- lm(narsp ~ . - msa, data = hprice)
summary(lm1)
```
All of the variables are statistically significant except for `ajwtr1` which is an indicator for whether the MSA is adjacent to the coastline. According to this linear model, the effect of time is negative since the coefficient for `time` is negative. This is contrary to what we observed in the graph above suggesting that a linear model isn't appropriate. The fixed effect of time suggests that average housing price drops over the years and that when you control for everything else, there is a negative trend with time. This doesn't appear to be the case in the marginal plot we made. 

3. Make a plot that shows how per-capita income changes over time. What is the nature of the increase? Make a similar plot to show how income growth changes over time. Comment on the plot.
```{r}
hprice %>%
  ggplot() + 
  geom_line(mapping = aes(x = time, y = ypc, color = msa),
            show.legend = FALSE) +
  scale_x_continuous("Year", 
                     labels = c("1986", "1988", "1990", "1992", "1994")) +
  ylab("Average Per Capita Income") 
```

The average per-capita income increases linearly over time. 

```{r}
hprice %>%
  ggplot() + 
  geom_line(mapping = aes(x = time, y = perypc, color = msa),
            show.legend = FALSE) +
  scale_x_continuous("Year", 
                     labels = c("1986", "1988", "1990", "1992", "1994")) +
  ylab("Percentage Growth in Per-Capita Income") 
```

The growth changes are generally stable and consistent except for 1991-1992 whever every MSA had a different trend. This suggests that the change in housing price is mainly modeled by the change in per-capita income and that the effect of time is actually negative when adjusting for per-capita income over time.

4. Create a new variable that is the per-capita income for the first time period for each MSA. Refit the same linear model but now using the initial income and not the income as it changes over time. Compare the two models.

```{r}
ypc_i <- data.frame(msa = unique(hprice$msa),
                  ypc_i = hprice$ypc[hprice$time == 1])
hprice <- merge(hprice, ypc_i, all.x = TRUE)
# hprice %>% head(3)
# hprice %>% tail(3)
```
```{r}
lm2 <- lm(narsp ~ .- msa - ypc, data = hprice)
summary(lm2)
```
The effect of initial average per capita income `ypc_i` is slightly more in this model than the previous model. In this model the effect of initial average per capita income is 8.865e-05 and in the previous model it is 7.029e-05. In both models `ypc_i` and `ypc` were both significant. The main difference is that the effect of `time` is now positive which is consistent with what we saw in our initial graphs. 

5. Fit a mixed effects model that has a random intercept for each MSA. Why might this be reasonable? The rest of the model should have the same structure as in the previous question. Make a numerical interpretation of the coefficient of time in your model. Explain the difference between REML and MLE methods.
```{r}
mem <- lmer(narsp ~ . - msa - ypc + (1 | msa), data = hprice, REML = FALSE)
summary(mem)
```
A random intercept is appropriate for this model since each MSA has different initial housing prices as we saw in the first plot. The random intercept helps to account for variability that we see in the initial housing prices. It seems it did a good job at capturing this variability since the random intercept effect has a higher standard deviation than the residual random effects. 

The coefficient of `time` is similar in this model to the previous. For every additional 2 years in time, the average sale prices in thousands of dollars in an MSA is estimated to increase by 3.68% (the dependent variable is log-transformed so there is a multiplicative effect and $\beta = 0.0368 = 3.68%$) on average, all else constant.

The maximum likelihood estimation method (MLE) is biased for the estimation of variance components. The restricted maximum likelihood estimation method (REML) tries to reduce bias in the variance components. The variance component parameters are estimated by MLE using transformed data and then fixed effects are estimated using general least squares. The REML estimate does not depend on the choice of transformation/bias in the model. 

6. Fit a model that omits the adjacent to water and rent control predictors. Test whether this reduction in the model can be supported.
```{r}
mem2 <- lmer(narsp ~ . - msa - ypc - ajwtr - rcdum + (1 | msa), data = hprice, REML = FALSE)
library(RLRsim)
#exactLRT(m=mem2, m0=mem)
lrt <- as.numeric(2*(logLik(mem, REML =F) - logLik(mem2, REML = F)))
pchisq(lrt, 2, lower.tail = F)
```
The p-value of the LRT is 0.12 which is greater than 0.05 which indicates that the smaller model (which doesn't include the variables of adjacent to water and rent control predictors) gives a better fit than the null model which includes those predictors.

7. It is possible that the increase in prices may not be linear in year. Fit an additive mixed model where smooth is added to year. Make a plot to show how prices have increased over time.
```{r}
library(mgcv)
gamm <- gamm(narsp ~ ypc_i + perypc + regtest + s(time, k = 9), random = list(msa = ~1),  data = hprice)
summary(gamm$gam)
hprice %>%
  ggplot() + 
  geom_line(mapping = aes(x = time, y = exp(narsp), color = msa),
            show.legend = FALSE) +
  scale_x_continuous("Year", 
                     labels = c("1986", "1988", "1990", "1992", "1994")) +
  ylab("Average Sale Price in Thousands of Dollars") 
```


8. Interpret the coefficients in the previous model for the initial annual income, growth and regulation predictors.

The following three coefficients are parametric in the model so they follow the general linear model interpretation.

- `ypc_i`: For every thousand dollar increase in initial average per capita income, average sale price (in thousands of dollars) increases by $e^{0.0001007} = 1.000101$, or .01% on average, all else constant. 

- `perypc`: For every 1% increase in growth in per-capita income, average sale price (in thousands of dollars) decreases by $e^{-0.0112156} = 0.9888471$ or decreases by 1.2% on average, all else constant. 

- `regtest`: For every increase in the regulatory environment index (more regulations), the average sale price (in thousands of dollars) increases by $e^{0.0355538} = 1.036193$ or roughly 3.6% on average, all else constant. 

```{r}
# hist(hprice$regtest)
# ggplot(hprice) + geom_point(aes(x = regtest, y = narsp))
```

## Optional Extra Credit Problem* 

>> This problem is meant to offer another chance to demonstrate understanding of some of the material on the mid-term. If you choose to do this problem and your score is higher than your mid-term grade, then your mid-term grade will be reweighted to be `New Midterm Grade = .8*Old Midterm Grade + .2*Extra Credit Problem`

The following table shows numbers of beetles dead after five hours exposure to gaseous carbon disulphide at various concentrations.

```{r}
(beetle <- tibble(dose = c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.8610, 1.8839),
                 beetles = c(59, 60, 62, 56, 63, 59, 62, 60),
                 killed = c(6, 13, 18, 28, 52, 53, 61, 60)))
```

1. Let $x_i$ be `dose`, $n_i$ be the number of beetles, and $y_i$ be the number of killed. Plot the proportions $p_i = y_i/n_i$ plotted against dose $x_i$. 
```{r}
ggplot(beetle) +
  geom_point(aes(x = dose, y = killed/beetles))
```


2. We fit a logistic model to understand the relationship between dose and the probability of being killed. Write out the logistic model and associated log-likelihood function. 

To fit a logistic model:
```{r}
beetlem1 <- glm(cbind(killed, beetles-killed) ~ dose, family = binomial, data = beetle)
summary(beetlem1)
```

$$
\mathbb{P}(Y_i = y_i) = \binom{n_i}{y_i} p_i^{y_i} (1 - p_i)^{n_i - y_i}
$$
using the inverse link function:
$$
p_i = \frac{e^{\eta_i}}{1 + e^{\eta_i}},
$$
and systematic component:
$$
\eta_i = \beta_0 + \beta_1 x_{i1} + \cdots + \beta_{q} x_{iq} = \mathbf{x}_i^T \boldsymbol{\beta}
$$

The associated log-likelihood is:
$$
\ell(\boldsymbol{\beta}) = \sum_{i=1}^n \left[ y_i \cdot \mathbf{x}_i^T \boldsymbol{\beta} - n_i \log ( 1 + e^{\mathbf{x}_i^T \boldsymbol{\beta}}) + \log \binom{n_i}{y_i} \right]
$$
3. Derive the scores, $\mathbf{U}$, with respect to parameters in the above logistic model. (Hint there are two parameters)

4. Derive the information matrix, $\mathcal{I}$ (Hint, a $2\times 2$ matrix)

5. Maximum likelihood estimates are obtained by solving the iterative equation

$$
\mathcal{I}^{(m-1)}\mathbf{b}^{(m)} = \mathcal{I}^{(m-1)}\mathbf{b}^{(m-1)}+ \mathbf{U}^{(m-1)}
$$
where $\mathbf{b}$ is the vector of estimates. Starting with $\mathbf{b}^{(0)} = 0$, implement this algorithm to show successive iterations are 



| Iterations      | $\beta_1$ | $\beta_2$| log-likelihood | 
|-----------------|-----------|----------|----------------|
|0 |       0 |       0| -333.404|
|1 | -37.856 | 21.337 | -200.010|
|2 | -53.853 | 30.384 | -187.274|
|3 |         |        |         | 
|4 |         |        |         | 
|5 |         |        |         | 
|6 | -60.717 | 34.270 | -186.235|


- If after 6 steps, the model converged. For this final model, calculate the deviance. What is the distribution the deviance has? 

- Does the model fit the data well? justify your answer. 

