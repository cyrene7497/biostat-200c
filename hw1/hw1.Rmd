---
title: "Biostat 200C Homework 1"
author: "Cyrene Arputhasamy"
subtitle: Due Apr 14 @ 11:59PM
output: 
  html_document:
    toc: true
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
```

To submit homework, please submit Rmd and html files to BruinLearn by the deadline.


## Q1. Reivew of linear models 
### The swiss data â€” use Fertility as the response to practice
```{r}
sessionInfo()
```
```{r}
library(tidyverse)
library(gtsummary)
```
```{r}
# Rename rows since each row is a province in Switzerland. 
swiss1 <- swiss %>% 
  as_tibble(rownames = "Province") %>% 
  print(width = Inf)
str(swiss1)
```
- An initial data analysis that explores the numerical and graphical characteristics of the data.
```{r}
summary(swiss1)
```
All variables are numeric besides `Province`. All except for `Fertility` are proportions of the population. `Fertility` is the common standardized fertility measure _I_g_, general fertility which is equal to the total number of children born to married women divided by the maximum conceivable number of births based on the expected fertility of the Hutterites, an Anabaptist sect who practiced universal marriage and no birth control in the early twentieth century (representing maximum expected fertility). 
```{r}
ggplot(data = swiss1) +
  geom_histogram(mapping = aes(x = Fertility)) + 
  labs(x = "Fertility Measure", y = "Number of Provinces")
```
At first glance it appears that there might be some outliers of unusually low and high fertility. 
```{r}
for (var in c("Agriculture", "Examination", "Education", "Catholic", "Infant.Mortality")) {
  plot <- ggplot(data = swiss1) + 
    geom_point(mapping = aes(x = get(var), y = Fertility)) +
    labs(x = var)
  print(plot)
}
```
There appears to be a distinct negative trend between `Examination` (% draftees receiving highest mark on army examination) and `Fertility`. Many of the provinces have a low percentage (0-20%) of draftees who were educated beyond primary school. There seems like there might be a relationship between `Fertility` and `Education`. The percent Catholic as opposed to Protestant seems to be in two groups. Generally provinces either had very high percentage of Catholics or quite low. There are few provinces with nearly 50-50 proportion between the two religions. We can try splitting `Catholic` into three levels `low`, `middle`, and `high`. 
```{r}
swiss1 <- swiss1 %>% 
  mutate(CatholicLevels = case_when(Catholic < 25 ~ "low",
                                    25 < Catholic & Catholic < 75 ~ "middle",
                                    75 < Catholic ~ "high")) %>%
  mutate(CatholicLevels = as.factor(CatholicLevels)) %>%
  print(width = Inf)
```

- Variable selection to choose the best model.

  For variable selection we start with a big model (`biglm`) that includes all two-way interactions between predictors. By step-wise regression, we minimize the AIC (Akaike Information Criterion) to get a small model (`smalllm`). 
```{r}
lmod <- lm(Fertility ~ Agriculture + Examination + Education + CatholicLevels + Infant.Mortality, swiss1)
summary(lmod)
biglm <- lm(Fertility ~ (Agriculture + Examination + Education + CatholicLevels + Infant.Mortality)^2, swiss1)
smalllm <- step(biglm, trace = TRUE)
drop1(smalllm, test = "F")
```
The F-test shows that the `Agriculture:Examination` and `CatholicLevels:Infant.Mortality` interaction terms can be dropped from the model. 

So the final model is:
```{r}
# final model
finallm <- lm(Fertility ~ Agriculture + Examination + CatholicLevels + 
                Infant.Mortality + Agriculture:CatholicLevels + 
                Agriculture:Infant.Mortality + Examination:Infant.Mortality,
              swiss1)
summary(finallm)
finallm %>%
  tbl_regression() %>%
  bold_labels() %>%
  bold_p(t = 0.05)
```
The fit of the model with the interactions is actually worse with the interaction terms than without.

- An exploration of transformations to improve the fit of the model.

Scatterplot of `Examination` and `Fertility` indicated that it might be helpful to transform `Examination` down the ladder of powers. 
```{r}
ggplot(data = swiss1) + 
    geom_point(mapping = aes(x = Examination^(-.5), y = Fertility))
```
The transformation makes the relationship slightly more linear.
```{r}
swiss1 <- swiss1 %>%
  mutate(TransformedExam = Examination^(-.5)) %>%
  print(width = Inf)
trlm <- lm(Fertility ~ Agriculture + TransformedExam + Education + 
             CatholicLevels + Infant.Mortality, swiss1)
summary(trlm)
```
The fit improves with the transformed `Examination` variable. We can run the selection again with this transformation. 
```{r}
bigtrlm <- lm(Fertility ~ (Agriculture + TransformedExam + Education + 
                             CatholicLevels + Infant.Mortality)^2, swiss1)
smalltrlm <- step(bigtrlm, trace = TRUE)
drop1(smalltrlm, test = "F")
```
The new final model is:
```{r}
finallm2 <- lm(Fertility ~ Agriculture + TransformedExam + Education + 
                 CatholicLevels + Infant.Mortality + 
                 Agriculture:TransformedExam +
                 Agriculture:CatholicLevels + Agriculture:Infant.Mortality + 
                 TransformedExam:CatholicLevels + 
                 TransformedExam:Infant.Mortality, swiss1)
summary(finallm2)
finallm2 %>%
  tbl_regression() %>%
  bold_labels() %>%
  bold_p(t = 0.05)
```


- Diagnostics to check the assumptions of your model.
```{r}
plot(finallm2)
swiss1 %>%
  mutate(cook = cooks.distance(finallm2)) %>%
  filter(cook >= 0.1) %>%
  print(width = Inf)
```
It appears the model assumptions are generally met. The Residuals vs Fitted plot shows the residuals randomly around zero. This means we are roughly meeting the linearity and constant variance assumptions. The Normal Q-Q plot is almost linear so we've met the normality assumption as well. However, the observation of the `Moutier` province has an unusually high cook's distance of 45. We can drop it and run the model again. 
```{r}
swiss2 <- swiss1 %>% filter(Province != "Moutier") %>% print(width = Inf)
```
```{r}
summary(lm(Fertility ~ Agriculture + TransformedExam + Education + 
                 CatholicLevels + Infant.Mortality + 
                 Agriculture:TransformedExam +
                 Agriculture:CatholicLevels + Agriculture:Infant.Mortality + 
                 TransformedExam:CatholicLevels + 
                 TransformedExam:Infant.Mortality, swiss2))
```
Removing the one outlier improved the fit. 

- Some predictions of future observations for interesting values of the predictors.
```{r}
set.seed(200)
pdf <- tibble(CatholicLevels = rep(levels(swiss2$CatholicLevels), 5),
              Agriculture = sample(swiss2$Agriculture, 15),
              TransformedExam = sample(swiss2$TransformedExam, 15),
              Education = sample(swiss2$Education, 15),
              Infant.Mortality = sample(swiss2$Infant.Mortality, 15)) %>% print()
pp <- predict(finallm2, new = pdf) %>% print()
pdf %>% mutate(predictedFertility = pp)
```

- An interpretation of the meaning of the model by writing a scientific abstract. (<150 words)

  + BACKGROUND: brief intro of the study background, what are the existing findings
  
  + OBJECTIVE: state the overall purpose of your research, e.g., what kind of knowledge gap you are trying to fill in
  
  + METHODS: study design (how these data were collected), outcome definitions, statistical procedures used
  
  + RESULTS: summary of major findings to address the question raised in objective
  
  + CONCLUSIONS:


## Q2. Concavity of logistic regression log-likelihood 

### Q2.1

Write down the log-likelihood function of logistic regression for Bernoulli responses.

Given $n$ data points $(y_i, \mathbf{x}_i)$, $i=1,\ldots,n$, the **log-likelihood** is
\begin{eqnarray*}
\ell(\boldsymbol{\beta}) &=& \sum_i \log \left[p_i^{y_i} (1 - p_i)^{1 - y_i}\right] \\
&=& \sum_i \left[ y_i \log p_i + (1 - y_i) \log (1 - p_i) \right] \\
&=& \sum_i \left[ y_i \log \frac{e^{\eta_i}}{1 + e^{\eta_i}} + (1 - y_i) \log \frac{1}{1 + e^{\eta_i}}  \right] \\
&=& \sum_i \left[ y_i \eta_i - \log (1 + e^{\eta_i}) \right] \\
&=& \sum_i \left[ y_i \cdot \mathbf{x}_i^T \boldsymbol{\beta} - \log (1 + e^{\mathbf{x}_i^T \boldsymbol{\beta}}) \right].
\end{eqnarray*}

### Q2.2

Derive the gradient vector and Hessian matrix of the log-likelihood function with respect to the regression coefficients $\boldsymbol{\beta}$. 



### Q2.3

Show that the log-likelihood function of logistic regression is a concave function in regression coefficients $\boldsymbol{\beta}$. (Hint: show that the negative Hessian is a positive semidefinite matrix.)

## Q3.  

The National Institute of Diabetes and Digestive and Kidney Diseases conducted a study on 768 adult female Pima Indians living near Phoenix. The purpose of the study was to investigate factors related to diabetes. The data may be found in the the dataset `pima`.
```{r}
library(faraway)
library(tidyverse)
pima1 <- as_tibble(pima) %>%
  print(width = Inf)
str(pima1)
```

### Q3.1

Create a factor version of the test results and use this to produce an interleaved histogram to show how the distribution of insulin differs between those testing positive and negative. Do you notice anything unbelievable about the plot?
```{r}
pima1$test_f <- as.factor(pima1$test)
pima1$test_f2 <- pima1$test_f
levels(pima1$test_f2) <- c("negative", "positive")
ggplot(pima1, aes(x = insulin, fill = test_f2)) +
  geom_histogram(alpha =.5, position = "identity") +
  ylab("Count") + xlab("Insulin (mu U/ml)") +
  ggtitle("Histogram of Insulin by Diabetes Test Results") +
  theme_bw()
```
It's unusual that there are so many entries of 0 Insulin, even for both positive and negative tested patients. It's impossible to have 0 insulin in the body so the zeros must be missing values. 
### Q3.2

Replace the zero values of `insulin` with the missing value code `NA`. Re-create the interleaved histogram plot and comment on the distribution.
```{r}
pima1$insulin[pima1$insulin == 0] <- NA
ggplot(pima1, aes(x = insulin, fill = test_f2)) +
  geom_histogram(alpha =.5, position = "identity") +
  ylab("Count") + xlab("Insulin (mu U/ml)") +
  ggtitle("Histogram of Insulin by Diabetes Test Results") +
  theme_bw()
```
The peak insulin level of those who tested negative is now lower than that of those who tested positive for diabetes. The distribution of those with a negative test looks right skewed. There also looks like there might be some outliers with unusually high insulin levels. 

### Q3.3

Replace the incredible zeroes in other variables with the missing value code. Fit a model with the result of the diabetes test as the response and all the other variables as predictors. How many observations were used in the model fitting? Why is this less than the number of observations in the data frame?
```{r}
summary(pima1)
```
The summary shows that `glucose`, `diastolic`, `triceps`, and `bmi`also have zero values that don't make sense. 
```{r}
pima1$glucose[pima1$glucose == 0] <- NA
pima1$diastolic[pima1$diastolic == 0] <- NA
pima1$triceps[pima1$triceps == 0] <- NA
pima1$bmi[pima1$bmi == 0] <- NA
summary(pima1)
```
```{r}
# Diabetes Test Model
dtm <- glm(test_f ~ pregnant + glucose + diastolic + triceps + insulin + bmi + 
             diabetes + age,
           family = "binomial", data = pima1)
summary(dtm)
```
There were 392 observations used in the model fitting. This is different from the number of observations because 376 observations were omitted due to missingness. 

### Q3.4

Refit the model but now without the insulin and triceps predictors. How many observations were used in fitting this model? Devise a test to compare this model with that in the previous question.
```{r}
# Diabetes Test Model 2
dtm2 <- glm(test_f ~ pregnant + glucose + diastolic + bmi + diabetes + age,
           family = "binomial", data = pima1)
summary(dtm2)
```
The model without insulin or triceps used 724 observation. There were 44 observations omitted due to missingness. To compare this model with the previous model our null hypothesis is that the addition of `insulin` and `triceps` as predictors does not improve model fit, and the alternative hypothesis is that their addition does improve model fit. To assess whether the full model is superior to the reduced model (diabetes test model 2 versus model 1), we can take the differences in deviance of the two models and compute the chi-square test statistic. The residual deviance in model 1 is 344.02 on 383 degrees of freedom, and in model 2 is 672.86 on 717 degrees of freedom. So the chi-square test statistic is $672.86 - 344.02 = 328.84$ on $717 - 383 = 334$ degrees of freedom. We compute the p-value:
```{r}
dtm <- glm(test_f ~ pregnant + glucose + diastolic + triceps + insulin + bmi + 
             diabetes + age,
           family = "binomial", data = na.omit(pima1))
dtm2 <- glm(test_f ~ pregnant + glucose + diastolic + bmi + diabetes + age,
           family = "binomial", data = na.omit(pima1))
anova(dtm, dtm2, test = "Chi")
```
The p-value is high so we accept the null hypothesis that the addition of `insulin` and `triceps` as predictors does not improve model fit. 

### Q3.5

Use AIC to select a model. You will need to take account of the missing values. Which predictors are selected? How many cases are used in your selected model?
```{r}
bigdtm <- glm(test_f ~ pregnant + glucose + diastolic + triceps + insulin + bmi + 
             diabetes + age, family = binomial, data = na.omit(pima1))
smalldtm <- stats::step(bigdtm, trace = TRUE)
summary(smalldtm)
```
After selection by AIC, the predictors `pregnant`, `glucose`, `bmi`, `diabetes`, and `age` were selected to be in the model. There were 392 observations included in this model. 

### Q3.6

Create a variable that indicates whether the case contains a missing value. Use this variable as a predictor of the test result. Is missingness associated with the test result? Refit the selected model, but now using as much of the data as reasonable. Explain why it is appropriate to do this.

```{r}
pima1$has_na <- ifelse(apply(is.na(pima1), 1, sum) > 0, 1, 0)
missings.glm <- glm(test_f2 ~ has_na, family = binomial, data = pima1)
summary(missings.glm)
```
Since the missing values are not associated with the diabetes test outcome, we can assume that the missing values are occurring randomly. Therefore even with a smaller sample size after omitting NAs the effect size is still valid because missingness is not associated with the outcome. 

```{r}
pima1 <- pima1 %>%
  drop_na(pregnant) %>%
  drop_na(glucose) %>%
  drop_na(bmi) %>%
  drop_na(diabetes) %>%
  drop_na(age) %>%
  print(width = Inf)
dtm_f <- glm(test_f ~ pregnant + glucose + bmi + diabetes + age, 
             family = binomial, data = pima1)
summary(dtm_f)
```
As opposed to the previous fit of this model with 392 observations, this fit uses 752 observations.

### Q3.7

Using the last fitted model of the previous question, what is the difference in the odds of testing positive for diabetes for a woman with a BMI at the first quartile compared with a woman at the third quartile, assuming that all other factors are held constant? Give a confidence interval for this difference.

```{r}
confint(dtm_f)
```
We see a 95% confidence interval for the log-odds of the `bmi` coefficient is given by about $(0.05921, 0.11701)$. This corresponds to the change in log-odds for a 1-unit increase in `bmi` We want a 9.3 unit increase in BMI, so we multiply the endpoints of the interval by 9.3 to get a confidence interval of $(0.5506403, 1.088167)$. Exponentiating this result gives a confidence interval of about $(1.734363, 2.968827)$. We can be 95% confident that the odds of testing positive for diabetes for a woman with a BMI at the 3rd quartile are between 1.73 and 2.96 times higher than the odds of testing positive for diabetes for a woman with a BMI at the 1st quartile, holding all other predictors constant.


### Q3.8 

Do women who test positive have higher diastolic blood pressures? Is the dias- tolic blood pressure significant in the regression model? Explain the distinction between the two questions and discuss why the answers are only apparently contradictory.