---
title: "Biostat 200C Homework 1"
author: "Cyrene Arputhasamy"
subtitle: Due Apr 14 @ 11:59PM
output: 
  html_document:
    toc: true
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
```

To submit homework, please submit Rmd and html files to BruinLearn by the deadline.


## Q1. Reivew of linear models 
### The swiss data â€” use Fertility as the response to practice
```{r}
sessionInfo()
```
```{r}
library(tidyverse)
library(gtsummary)
```
```{r}
# Rename rows since each row is a province in Switzerland. 
swiss1 <- swiss %>% 
  as_tibble(rownames = "Province") %>% 
  print(width = Inf)
str(swiss1)
```
- An initial data analysis that explores the numerical and graphical characteristics of the data.
```{r}
summary(swiss1)
```
All variables are numeric besides `Province`. All except for `Fertility` are proportions of the population. `Fertility` is the common standardized fertility measure _I_g_, general fertility which is equal to the total number of children born to married women divided by the maximum conceivable number of births based on the expected fertility of the Hutterites, an Anabaptist sect who practiced universal marriage and no birth control in the early twentieth century (representing maximum expected fertility). 
```{r}
ggplot(data = swiss1) +
  geom_histogram(mapping = aes(x = Fertility)) + 
  labs(x = "Fertility Measure", y = "Number of Provinces")
```
At first glance it appears that there might be some outliers of unusually low and high fertility. 
```{r}
for (var in c("Agriculture", "Examination", "Education", "Catholic", "Infant.Mortality")) {
  plot <- ggplot(data = swiss1) + 
    geom_point(mapping = aes(x = get(var), y = Fertility)) +
    labs(x = var)
  print(plot)
}
```
There appears to be a distinct negative trend between `Examination` (% draftees receiving highest mark on army examination) and `Fertility`. Many of the provinces have a low percentage (0-20%) of draftees who were educated beyond primary school. There seems like there might be a relationship between `Fertility` and `Education`. The percent Catholic as opposed to Protestant seems to be in two groups. Generally provinces either had very high percentage of Catholics or quite low. There are few provinces with nearly 50-50 proportion between the two religions. We can try splitting `Catholic` into three levels `low`, `middle`, and `high`. 
```{r}
swiss1 <- swiss1 %>% 
  mutate(CatholicLevels = case_when(Catholic < 25 ~ "low",
                                    25 < Catholic & Catholic < 75 ~ "middle",
                                    75 < Catholic ~ "high")) %>%
  mutate(CatholicLevels = as.factor(CatholicLevels)) %>%
  print(width = Inf)
```

- Variable selection to choose the best model.

  For variable selection we start with a big model (`biglm`) that includes all two-way interactions between predictors. By step-wise regression, we minimize the AIC (Akaike Information Criterion) to get a small model (`smalllm`). 
```{r}
lmod <- lm(Fertility ~ Agriculture + Examination + Education + CatholicLevels + Infant.Mortality, swiss1)
summary(lmod)
biglm <- lm(Fertility ~ (Agriculture + Examination + Education + CatholicLevels + Infant.Mortality)^2, swiss1)
smalllm <- step(biglm, trace = TRUE)
drop1(smalllm, test = "F")
```
The F-test shows that the `Agriculture:Examination` and `CatholicLevels:Infant.Mortality` interaction terms can be dropped from the model. 

So the final model is:
```{r}
# final model
finallm <- lm(Fertility ~ Agriculture + Examination + CatholicLevels + 
                Infant.Mortality + Agriculture:CatholicLevels + 
                Agriculture:Infant.Mortality + Examination:Infant.Mortality,
              swiss1)
summary(finallm)
finallm %>%
  tbl_regression() %>%
  bold_labels() %>%
  bold_p(t = 0.05)
```
The fit of the model with the interactions is actually worse with the interaction terms than without.

- An exploration of transformations to improve the fit of the model.

Scatterplot of `Examination` and `Fertility` indicated that it might be helpful to transform `Examination` down the ladder of powers. 
```{r}
ggplot(data = swiss1) + 
    geom_point(mapping = aes(x = Examination^(-.5), y = Fertility))
```
The transformation makes the relationship slightly more linear.
```{r}
swiss1 <- swiss1 %>%
  mutate(TransformedExam = Examination^(-.5)) %>%
  print(width = Inf)
trlm <- lm(Fertility ~ Agriculture + TransformedExam + Education + 
             CatholicLevels + Infant.Mortality, swiss1)
summary(trlm)
```
The fit improves with the transformed `Examination` variable. We can run the selection again with this transformation. 
```{r}
bigtrlm <- lm(Fertility ~ (Agriculture + TransformedExam + Education + 
                             CatholicLevels + Infant.Mortality)^2, swiss1)
smalltrlm <- step(bigtrlm, trace = TRUE)
drop1(smalltrlm, test = "F")
```
The new final model is:
```{r}
finallm2 <- lm(Fertility ~ Agriculture + TransformedExam + Education + 
                 CatholicLevels + Infant.Mortality + 
                 Agriculture:TransformedExam +
                 Agriculture:CatholicLevels + Agriculture:Infant.Mortality + 
                 TransformedExam:CatholicLevels + 
                 TransformedExam:Infant.Mortality, swiss1)
summary(finallm2)
finallm2 %>%
  tbl_regression() %>%
  bold_labels() %>%
  bold_p(t = 0.05)
```


- Diagnostics to check the assumptions of your model.
```{r}
plot(finallm2)
swiss1 %>%
  mutate(cook = cooks.distance(finallm2)) %>%
  filter(cook >= 0.1) %>%
  print(width = Inf)
```
It appears the model assumptions are generally met. The Residuals vs Fitted plot shows the residuals randomly around zero. This means we are roughly meeting the linearity and constant variance assumptions. The Normal Q-Q plot is almost linear so we've met the normality assumption as well. However, the observation of the `Moutier` province has an unusually high cook's distance of 45. We can drop it and run the model again. 
```{r}
swiss2 <- swiss1 %>% filter(Province != "Moutier") %>% print(width = Inf)
```
```{r}
summary(lm(Fertility ~ Agriculture + TransformedExam + Education + 
                 CatholicLevels + Infant.Mortality + 
                 Agriculture:TransformedExam +
                 Agriculture:CatholicLevels + Agriculture:Infant.Mortality + 
                 TransformedExam:CatholicLevels + 
                 TransformedExam:Infant.Mortality, swiss2))
```
Removing the one outlier improved the fit. 

- Some predictions of future observations for interesting values of the predictors.
```{r}
set.seed(200)
pdf <- tibble(CatholicLevels = rep(levels(swiss2$CatholicLevels), 5),
              Agriculture = sample(swiss2$Agriculture, 15),
              TransformedExam = sample(swiss2$TransformedExam, 15),
              Education = sample(swiss2$Education, 15),
              Infant.Mortality = sample(swiss2$Infant.Mortality, 15)) %>% print()
pp <- predict(finallm2, new = pdf) %>% print()
pdf %>% mutate(predictedFertility = pp)
```

- An interpretation of the meaning of the model by writing a scientific abstract. (<150 words)

  + BACKGROUND: brief intro of the study background, what are the existing findings
  
  + OBJECTIVE: state the overall purpose of your research, e.g., what kind of knowledge gap you are trying to fill in
  
  + METHODS: study design (how these data were collected), outcome definitions, statistical procedures used
  
  + RESULTS: summary of major findings to address the question raised in objective
  
  + CONCLUSIONS:


## Q2. Concavity of logistic regression log-likelihood 

### Q2.1

Write down the log-likelihood function of logistic regresion for binomial responses.

### Q2.2

Derive the gradient vector and Hessian matrix of the log-likelhood function with respect to the regression coefficients $\boldsymbol{\beta}$. 

### Q2.3

Show that the log-likelihood function of logistic regression is a concave function in regression coefficients $\boldsymbol{\beta}$. (Hint: show that the negative Hessian is a positive semidefinite matrix.)

## Q3.  

The National Institute of Diabetes and Digestive and Kidney Diseases conducted a study on 768 adult female Pima Indians living near Phoenix. The purpose of the study was to investigate factors related to diabetes. The data may be found in the the dataset `pima`.

### Q3.1

Create a factor version of the test results and use this to produce an interleaved histogram to show how the distribution of insulin differs between those testing positive and negative. Do you notice anything unbelievable about the plot?

### Q3.2

Replace the zero values of `insulin` with the missing value code `NA`. Recreatethe interleaved histogram plot and comment on the distribution.

### Q3.3

Replace the incredible zeroes in other variables with the missing value code. Fit a model with the result of the diabetes test as the response and all the other variables as predictors. How many observations were used in the model fitting? Why is this less than the number of observations in the data frame.

### Q3.4

Refit the model but now without the insulin and triceps predictors. How many observations were used in fitting this model? Devise a test to compare this model with that in the previous question.

### Q3.5

Use AIC to select a model. You will need to take account of the missing val- ues. Which predictors are selected? How many cases are used in your selected model?

### Q3.6

Create a variable that indicates whether the case contains a missing value. Use this variable as a predictor of the test result. Is missingness associated with the test result? Refit the selected model, but now using as much of the data as reasonable. Explain why it is appropriate to do this.

### Q3.7

Using the last fitted model of the previous question, what is the difference in the odds of testing positive for diabetes for a woman with a BMI at the first quartile compared with a woman at the third quartile, assuming that all other factors are held constant? Give a confidence interval for this difference.

### Q3.8 

Do women who test positive have higher diastolic blood pressures? Is the dias- tolic blood pressure significant in the regression model? Explain the distinction between the two questions and discuss why the answers are only apparently contradictory.