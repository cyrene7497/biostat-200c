---
title: "Biostat 200C Homework 4"
author: "Cyrene Arputhasamy"
subtitle: Due May 12  @ 11:59PM
output: 
  html_document:
    toc: true
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
```

```{r}
library(faraway)
library(dplyr)
```

## Q1. ELMR Excercise 7.5 (p150)
The `debt` data arise from a large postal survey on the psychology of debt. The frequency of credit card use is a three-level factor ranging from `never`, through `occasionally` to `regularly`.

### 5a
Declare the response as an ordered factor and make a plot showing the relationship to `prodebt`. Comment on the plot. Use a table or plot to display the relationship between the response and the income group.
```{r}
debt$ccarduse <- ordered(debt$ccarduse, levels = c(1, 2, 3))
library(ggplot2)
ggplot(debt, aes(x = ccarduse, y = prodebt)) + geom_boxplot()
ggplot(debt, aes(x = ccarduse, y = incomegp)) + geom_boxplot()
debt %>%
  xtabs( ~ ccarduse + incomegp, .)
```
There is a little variability in `prodebt` across groups of card use. There is a general trend that those scoring high in `prodebt`, having a general favorable attitude to debt, score higher in credit card use. It also seems that those with high credit card use are generally in higher income groups. 

### 5b
Fit a proportional odds model for credit card use with all the other variables as predictors. What are the two most significant predictors (largest t-values) and what is their qualitative effect on the response? What is the least significant predictor?
```{r}
library(MASS)
pocc <- polr(ccarduse ~ ., data = debt)
summary(pocc)
exp(pocc$coef[1])
exp(pocc$coef[6])
```
The two most significant predictors are `incomegp` (income group) and `bankacc` (whether or not the respondent has a bank account). The least significant predictor is `house` (the security of housing tenure). The odds of moving from `never` to `occassional` credit card use **or** from `occasional` to `regularly` using a credit card increases by a factor of 1.6 $(e^{0.47131})$ when income group increases one level. The odds of moving from `never` to `occassional` credit card use **or** from `occasional` to `regularly` using a credit card increases by a factor of 8.18 when an individual has a bank account as compared to not having a bank account. 

### 5c
Fit a proportional odds model using only the least significant predictor from the previous model. What is the significance of this predictor in this small model? Are the conclusions regarding this predictor contradictory for the two models?
```{r}
pocc2 <- polr(ccarduse ~ house, data = debt)
summary(pocc2)
pt(3.895, 3, lower.tail = FALSE)
```
The significance of this predictor now has a p-value of 0.01 which is significant. This is contradictory to the previous model. 

### 5d
Use stepwise AIC to select a smaller model than the full set of predictors. You will need to handle the missing values carefully. Report on the qualitative effect of the predictors in your chosen model. Can we conclude that the predictors that were dropped from the model have no relation to the response?
```{r}
debt2 <- debt %>% drop_na()
poccf <- polr(ccarduse ~ ., data = debt2)
(poccf2 <- step(poccf, trace = FALSE))
```
By step-wise AIC selection, six variables were dropped. The odds of moving from `never` to `occassional` credit card use **or** from `occasional` to `regularly` using a credit card increases by a factor of exp(0.4588585) = 1.58 when moving up one group in `incomegp`. The odds of moving from one level of credit card use to the next increases by a factor of exp(0.2695623) = 1.309391 when `agegp` increases. Having a bank account (`bankacc`) increases the odds of moving from one level of credit card use to the next by a factor of exp(2.0815757) = 8.01 times. The odds of moving from one level of credit card use to the next increases by a factor of exp(0.5047742) = 1.65 when the responded has a building society account (`bsocacc`). Buying cigarettes (`cigbuy`) decreases the odds of moving from one level of credit card use to the next by a factor of exp(-0.7677124) = 0.4640735 or decreases by 54%. Scoring higher on the scale of attitude toward debt increases the odds of moving from one level of credit card use to the next by a factor of exp(0.5635449) = 1.756889. This does not mean that the predictors dropped from the model have no relation to the response. 

### 5e
Compute the median values of the predictors in your selected model. At these median values, contrast the predicted outcome probabilities for both smokers and nonsmokers.
```{r}
debt2 %>%
  dplyr::select(incomegp, agegp, bankacc, bsocacc, cigbuy, prodebt) %>%
  apply(., 2, median)
predict(poccf2, data.frame(incomegp = 3, agegp = 2, bankacc = 1, bsocacc = 1, cigbuy = 0, prodebt = 3.18), type = "probs")
predict(poccf2, data.frame(incomegp = 3, agegp = 2, bankacc = 1, bsocacc = 1, cigbuy = 1, prodebt = 3.18), type = "probs")
```
The predicted outcome probabilities for never using a credit card (level 1) is .42 for non smokers and .61 for smokers. The predicted probability of occasionally using a credit card is lower for smokers than non-smokers at .25 compared to .32. The predicted probability of regularly using a credit card is .24 for non-smokers and .13 for smokers. 

### 5f
Fit a proportional hazards model to the same set of predictors and recompute the two sets of probabilities from the previous question. Does it make a difference to use this type of model?
```{r}
phcc <- polr(ccarduse ~ incomegp + agegp + bankacc + bsocacc + cigbuy + prodebt, method = "cloglog", data = debt2)
predict(phcc, data.frame(incomegp = 3, agegp = 2, bankacc = 1, bsocacc = 1, cigbuy = 0, prodebt = 3.18), type = "probs")
predict(phcc, data.frame(incomegp = 3, agegp = 2, bankacc = 1, bsocacc = 1, cigbuy = 1, prodebt = 3.18), type = "probs")
```
Fitting the model as a proportional hazards model only slightly changed the predicted probabilities in this example. It doesn't seem to make a difference to use this type of model.


## Q2. Moments of exponential family distributions

Show that the exponential family distributions have moments
\begin{eqnarray*}
  \mathbb{E}Y &=& \mu = b'(\theta) \\
  \operatorname{Var}Y &=& \sigma^2 = b''(\theta) a(\phi).
\end{eqnarray*}


## Q3. Score and information matrix of GLM

Derive the gradient (score), negative Hessian, and Fisher information matrix (expected negative Hessian) of GLM.

For GLM, 
\begin{eqnarray*}
  \ell(\boldsymbol{\beta}) &=& \sum_{i=1}^n \frac{y_i \theta_i - b(\theta_i)}{a(\phi)} + c(y_i, \phi) \\
\end{eqnarray*}

The gradient (score) is,
\begin{eqnarray*}
\nabla \ell_i(\boldsymbol{\beta}) &=& \frac{y_i - b'(\theta_i)}{a(\phi)} \nabla_{\boldsymbol{\beta}} \theta_i \\
&=& \frac{y_i - b'(\theta_i)}{a(\phi)} \cdot \frac{d\theta_i}{d\mu_i} \cdot \nabla_{\boldsymbol{\beta}} \mu_i.
\end{eqnarray*}

because
\begin{eqnarray*}
\mathbb{E}Y_i = \mu_i = b'(\theta_i)
\frac{d \mu_i}{d \theta_i} = b''(\theta_i)
\end{eqnarray*}

rearranging gives
\begin{eqnarray*}
\frac{d \theta_i}{d \mu_i} = \frac{1}{b''(\theta_i)}
\end{eqnarray*}

And since for GLM
\begin{eqnarray*}
g(\mu_i) = \bold{x}_i^T\beta = \eta_i
\mu_i(\eta_i) = g^{-1}(\eta_i)
\frac{d \mu_i}{d \eta_i} = \mu_i'(\eta_i)
\end{eqnarray*}

Furthermore, 
\begin{eqnarray*}
\eta_i = \bold{x}_i^T\beta
\frac{d \eta_i}{d \beta_i} = \bold{x}_i
\end{eqnarray*}

Combining all these parts and using the chain rule,
\begin{eqnarray*}
\frac{d \ell}{d \beta} = \frac{d \ell}{d \theta_i} \cdot \frac{d theta_i}{d \mu_i} \cdot \frac{d mu_i}{d \eta_i} \cdot \frac{d \eta_i}{d \beta} \\
\nabla \ell_i(\boldsymbol{\beta}) &=& \frac{y_i - b'(\theta_i)}{a(\phi)} \cdot \frac{1}{b''(\theta_i)} \cdot \mu_i'(\eta_i) \cdot \bold{x}_i \\
&=& \frac{(y_i - \mu_i) \mu_i'(\eta_i)}{\sigma_i^2}\bold{x}_i 
\end{eqnarray*}

because
\begin{eqnarray*}
\mu = b'(\theta)
\operatorname{Var}Y &=& \sigma^2 = b''(\theta) a(\phi)
\end{eqnarray*}

For the Hessian, 

GLM notes hw4 hint. the key is trying to understand the relationship between mu and sigma i squ. the systematic component eta equals xB. mu is a function of eta. in logistic regression mu = e^xb/1+e^xB. mu func of eta, eta a func of beta. take that into consideration when you do the derivative. in the hint i didn't take the cannonic link into consideration. these derivations are based on not using the cannonic link. 
der log likelihood w respect to beta. theta is one parameter in exp family. the first step is derivative w respect to beta but a(phi) is a constant and the second term is gone. def first w respect to theta, then der of theta w respect to beta. first w respect to theta, then beta. then need a relationship to have a direct relationship w beta. theta w respect to mu. my is a functino of eta which is a function of beta. 

taking the seconf deri gives.. the second term can be the same as the third term. use the relationship to take another deriv. sigma i sq so when you take another der by chair rule you can show it gives you another dsigma sq. take another def from the last term and plug into mu'' and get the same as the second term. 

## Q4. ELMR Exercise 8.1 (p171)

Data is generated from the exponential distribution with density $f(y) = \lambda e^{-\lambda y}$ where $\lambda, y > 0$. 

### 1a 
Identify the specific form of $\theta, \phi, a() , b()$ and $c()$ for the exponential distribution.

The exponential distribution is a special case of the gamma distribution. 
\begin{eqnarray*}
f(y) = e^{- \lambda y + \log{\lambda}}
\end{eqnarray*}
so
\begin{eqnarray*}
\theta = - \lambda, b(\theta) = - \log\lambda = -\log(-\theta) \\
\phi = 1, a(\phi) = 1, c(y, \phi) = 0
\end{eqnarray*}

### 1b

What is the canonical link and variance function for a GLM with a response following the exponential distribution?
\begin{eqnarray*}
b'(\theta) = \frac{d}{d \theta} [- \log(- \theta)] = -\frac{1}{\theta} \\
\mathbb{E}Y = -\frac{1}{\theta} = \frac{1}{\lambda} = \mu
\end{eqnarray*}
The canonical form expresses $\theta$ as a function of $\mu$ so $\theta(\mu) = -\frac{1}{\mu}$
\begin{eqnarray*}
\operatorname{Var}Y &=& b''(\theta) a(\phi) = \frac{d}{d \theta} [- \frac{1}{\theta}] = \frac{1}{\theta^2} = \mu^2
\end{eqnarray*}

### 1c
Identify a practical difficulty that may arise when using the canonical link in this instance.

In this case, modeling the canonical link as a linear combination of predictors can result in a negative mean.

### 1d
When comparing nested models in this case, should an F or $\chi^2$ test be used? Explain.

The dispersion parameter $\phi = 1$. We can compare the models using the deviance test with $\chi^2$ as the reference distribution. The F test is used when the dispersion is estimated, but in this case we know the dispersion.

### 1e
Express the deviance in this case in terms of the responses $y_i$ and the fitted values $\hat{\mu}_i$.

\begin{eqnarray*}
D &=& 2 \sum(\frac{y_i-\hat{\mu}_i}{\hat{\mu}_i} - \log\frac{y_i}{\hat{\mu}_i})
\end{eqnarray*}

## Q5. ELMR Exercise 8.4 (p172)
Consider the Galápagos data (`gala`) and model analyzed in this chapter. The purpose of this question is to reproduce the details of the GLM fitting of this data.

### 4a
Fit a Poisson model to the species response with the five geographic variables as predictors. Do not use the endemics variable. Report the values of the coefficients and the deviance.
```{r}
pm <- glm(Species ~ . - Endemics, family = poisson, data = gala)
summary(pm)
```
The coefficients of `Area`, `Elevation`, `Nearest`, `Scruz`, and `Adjacent` are `-0.0005799`, `0.003541`, `0.00826`, `-0.005709`, and `-0.000663` respectively and the residual deviance is 716.85 which is very high. 

### 4b
For a Poisson GLM, derive $\eta$, $d\eta /dμ$, V(μ) and the weights to be used in an iteratively fit GLM. What is the form of the adjusted dependent variable here?

\begin{eqnarray*}
\eta = \log\mu \\
\frac{d \eta}{d \mu} = \frac{1}{\mu} \\
V(\mu) = \mu \\
\frac{1}{w} = (\frac{d\eta}{d\mu})^2 V(\hat{\mu}^{<0>}) \\
= (\frac{1}{\mu})^2 \cdot \mu = \frac{1}{\mu} \\
w = \mu
z^i = \hat{\eta}^i + (y - \hat{\mu}^i)\frac{d\eta}{d\mu}
 = \log\hat{\mu} + \frac{(y - \hat{\mu})}{\mu}
\end{eqnarray*}

### 4c

Using the observed response as initial values, compute the first stage of the iteration, stopping after the first linear model fit. Compare the coefficients of this linear model to those found in the GLM fit. How close are they?

```{r}
gala %>% nrow()
# First iteration
y <- gala$Species/30; mu <- y
eta <- log(mu)
z <- eta + (y-mu)/mu
w <- mu
lmod <- lm(z ~ . - Endemics - Species, weights = w, gala)
coef(lmod)
deviance(lmod)
```
The coefficients of the first iteration are very close to the Poisson model.

### 4d
Continue the iteration to get the next $\eta$ and μ. Use this to compute the current value of the deviance. How close is this to the deviance from the GLM?

```{r}
#Second Iteration
eta <- lmod$fitted.values
mu <- exp(eta)
z <- eta + (y-mu)/mu
w <- mu
lmod <- lm(z ~ . - Endemics - Species, weights = w, gala)
coef(lmod)
deviance(lmod)
```

The deviance of this model is much lower than that of the GLM and is closer to the degrees of freedom.

### 4e
Compute one more iteration of the GLM fit, reporting the next calculation of the coefficients and deviance. How close are these to target now?

```{r}
# Third Iteration
eta <- lmod$fitted.values
mu <- exp(eta)
z <- eta + (y-mu)/mu
w <- mu
lmod <- lm(z ~ . - Endemics - Species, weights = w, gala)
coef(lmod)
deviance(lmod)
```

These values are yet closer to the target.

### 4f
Repeat these iterations a few more times,computing the deviance in each time. Stop when the deviance does not change much. Compare your final estimated coefficients to that produced by the GLM fit.
```{r}
# Fourth Iteration
eta <- lmod$fitted.values
mu <- exp(eta)
z <- eta + (y-mu)/mu
w <- mu
lmod <- lm(z ~ . - Endemics - Species, weights = w, gala)
coef(lmod)
deviance(lmod)
```

```{r}
# Fifth Iteration
eta <- lmod$fitted.values
mu <- exp(eta)
z <- eta + (y-mu)/mu
w <- mu
lmod <- lm(z ~ . - Endemics - Species, weights = w, gala)
coef(lmod)
deviance(lmod)
```
The deviance and coefficients are no longer changing after the 4th iteration. The estimated intercept is quite different, even a different sign, but the coefficients of the predictors are almost exactly the same as the GLM estimates. 

### 4g
Use your final iterated linear model fit to produce standard errors for the coefficients. How close are these to that produced by the direct GLM fit?
```{r}
sqrt(diag(vcov(lmod)))
```
The standard error was lower for all the estimated coefficients in the GLM. They're off by an order of roughly 10. 


## Q6. ELMR Exercise 8.5 (p172)
Again using the Galápagos data, fit a Poisson model to the species response with the five geographic variables as predictors. Do not use the endemics variable. The purpose of this question is to compare six different ways of testing the significance of the elevation predictor, i.e., $H_0 : \beta_{Elev} = 0$. In each case, report the p-value.

### 5a

Use the z-statistic from the model summary.
```{r}
summary(pm)$coefficients[,4]
```

The p-value for `Elevation` is essentially 0 and thus us significant.

### 5b
Fit a model without elevation and use the difference in deviances to make the test.
```{r}
pm2 <- glm(Species ~ . - Endemics - Elevation, family = poisson, data = gala)
summary(pm2)
pchisq(deviance(pm2) - deviance(pm), pm$df - pm2$df, lower = F)
```
The p-value is also essentially zero so we can conclude that `Elevation` improves the model fit and is significant.

### 5c
Use the Pearson Chi-squared statistic in place of the deviance in the previous test.
```{r}
px2 <- sum(residuals(pm, type = "pearson")^2)
pchisq(px2, pm$df.residual, lower.tail = FALSE)
```
The small p-value indicates that the model doesn't fit the data well. 
```{r}
px2.1 <- sum(residuals(pm2, type = "pearson")^2)
pchisq(px2.1, pm2$df.residual, lower.tail = FALSE)
```
The model without `Elevation` has an even smaller p-value than with `Elevation` so the model without `Elevation` fits worse than when it is included in the model.

### 5d
Fit the Poisson model with a free dispersion parameter as described in Section 5.2. Make the test using the model summary.

```{r}
dp <- sum(residuals(pm, type = "pearson")^2)/pm$df.residual
dp2 <- sum(residuals(pm2, type = "pearson")^2)/pm2$df.residual
summary(pm, dispersion = dp)
summary(pm2, dispersion = dp2)
```
`Elevation` is still significant with the free dispersion parameter. 

### 5e
Use the sandwich estimation method for the standard errors in the original
model. Use these to compute z-statistics.

### 5f
Use the robust GLM estimation method and report the test result from the
summary.

### 5g
Compare all six results. Pick the best one and justify your choice.